{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Ranking:\n",
    "        1.1 Hierarchical Clustering (ranking_prediction.ipynb)\n",
    "        1.2 Map labels to future matches as home and away of past season\n",
    "            1.2.1 If team is new, label it as normal (which is a not promoted team)\n",
    "        1.3 Compute difference in ranking (NO because of no sequential)\n",
    "        1.4 Future work: study the week development of the league to see if there is a point where\n",
    "            it can be started to predict the actual behavior of the team as the promotion label\n",
    "    Prediction:\n",
    "        2.0 Drop features --> computation differences (visualization.ipynb)\n",
    "        2.1 Features TEST\n",
    "            2.1.0 First match as median of past season (already started) TODO\n",
    "            2.1.2 Median of current season (home and away games are definetely a factor)\n",
    "            2.1.2.1 Median at home/away <-- Just this\n",
    "            2.1.2.2 Past average of last n games (test with 3, 5, etc)\n",
    "            2.1.2.3 Average of last n games at home/away\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import playstyle\n",
    "import ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Everything to create the clusters\n",
    "\"\"\"\n",
    "from sklearn import preprocessing\n",
    "from scipy.cluster.hierarchy import linkage, cophenet, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Returns Z, coph_matrix and best cophence score from HC\n",
    "def HierarchicalClustering(data, label):\n",
    "    methods = [\"single\",\"complete\",\"average\",\"centroid\",\"ward\"]\n",
    "\n",
    "    # Pass the dataset into pdist to get your proximity matrix for calculating CPCC\n",
    "    proximity_matrix = pdist(data)\n",
    "\n",
    "    best_coph = -1\n",
    "    best_method = None\n",
    "\n",
    "    for method in methods:\n",
    "        Z = linkage(data, method)\n",
    "        coph, coph_matrix = cophenet(Z, proximity_matrix)\n",
    "        if coph > best_coph:\n",
    "            best_coph = coph\n",
    "            best_method = method\n",
    "            best_matrix = coph_matrix\n",
    "        Z = linkage(data, best_method)\n",
    "        coph_matrix = cophenet(Z)\n",
    "    return Z, coph_matrix, best_coph\n",
    "\n",
    "#Returns a dictionary with the clusters in the form\n",
    "#\"id\": \"season\" : point -> Attr object\n",
    "def dct_clusters(dct_clusters, Z, coph_matrix, dendo_label, criterion='distance', real=None):\n",
    "    if real != None:\n",
    "        clusters = real[2]\n",
    "    else:\n",
    "        clusters = fcluster(Z, t=coph_matrix[0], criterion=criterion)\n",
    "    for i in range(0, len(dendo_label)):\n",
    "        point = ranking.Attr(dendo_label[i], clusters[i])\n",
    "        if point.value2 not in dct_clusters:\n",
    "            dct_clusters[point.value2] = {}\n",
    "            dct_clusters[point.value2][point.value3] = point\n",
    "        else:\n",
    "            dct_clusters[point.value2][point.value3] = point\n",
    "    return dct_clusters, clusters\n",
    "\n",
    "# Return the cluster of an specific type\n",
    "def get_cluster_of_type(all_dct, country, league, seasons, target_col, clean_type, real=None):\n",
    "    # Data initialization\n",
    "    data, column_names = ranking.concat_data(country, league, seasons, target_col, clean_type)\n",
    "    all_data, all_season, all_names, all_target = ranking.get_all_data(data, len(target_col))\n",
    "    # Use Agglomerative\n",
    "    all_data = preprocessing.StandardScaler().fit_transform(all_data)\n",
    "    dendo_label = ranking.label_team_season(all_names, all_season)\n",
    "    Z, coph_matrix, coph = HierarchicalClustering(all_data, dendo_label)\n",
    "    if real == None:\n",
    "        all_dct, all_lst = dct_clusters(all_dct, Z, coph_matrix, dendo_label)\n",
    "    else:\n",
    "        all_dct, all_lst = dct_clusters(all_dct, Z, coph_matrix, dendo_label, real=all_target)\n",
    "    return all_dct\n",
    "\n",
    "#Returns three clusters as: overall, home and away performance\n",
    "def get_clusters(country, league, season, year_window=1):\n",
    "    # Historicity: multi season directory\n",
    "    start_season = season\n",
    "    seasons = list(range(start_season, start_season - year_window, -1))\n",
    "    seasons = sorted(seasons, reverse=True)\n",
    "    # Targets\n",
    "    target_col = [\"rank\", \"points\", \"description\"]\n",
    "    # Gets the dictionary\n",
    "    overall_dct = dict()\n",
    "    home_dct = dict()\n",
    "    away_dct = dict()\n",
    "    real_dct = dict()\n",
    "    for season in seasons:\n",
    "        season = [season]\n",
    "        real_dct = get_cluster_of_type(overall_dct, country, league, season, target_col, clean_type=None, real=True)\n",
    "        overall_dct = get_cluster_of_type(overall_dct, country, league, season, target_col, clean_type=None)\n",
    "        home_dct = get_cluster_of_type(home_dct, country, league, season, target_col, clean_type='home')\n",
    "        away_dct = get_cluster_of_type(away_dct, country, league, season, target_col, clean_type='away')\n",
    "    return (overall_dct, home_dct, away_dct, real_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Creates the statistics dataset\n",
    "\"\"\"\n",
    "def get_statistics(country, league, curr_week, season, year_window=1):\n",
    "    # Historicity: multi season directory\n",
    "    start_season = season\n",
    "    seasons = list(range(start_season-1, start_season - year_window, -1))\n",
    "    seasons = sorted(seasons, reverse=True)\n",
    "    # Data initialization\n",
    "    data = []\n",
    "    # Current week\n",
    "    df, target = playstyle.df_season(country, league, season, curr_week, drop_goals=False)\n",
    "    tup = (season, df, target)\n",
    "    data.append(tup)\n",
    "    # Past years\n",
    "    for season in seasons:\n",
    "        df, target = playstyle.df_season(country, league, season, 38, drop_goals=False)\n",
    "        tup = (season, df, target)\n",
    "        data.append(tup)\n",
    "    all_data, all_target = playstyle.get_all(data)\n",
    "    return all_data, all_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Function that maps the dataset with the clusters\n",
    "\"\"\"\n",
    "def max_appearance_rank(dct, season):\n",
    "    dct_rank = dict()\n",
    "    season = str(int(season))\n",
    "    for team in dct:\n",
    "        if season in dct[team]:\n",
    "            rank = dct[team][season].value\n",
    "            if rank not in dct_rank:\n",
    "                dct_rank[rank] = 1\n",
    "            else:\n",
    "                dct_rank[rank] += 1\n",
    "    return max(dct_rank.keys(), key=dct_rank.get)\n",
    "\n",
    "def get_rank(df, dct, team):\n",
    "    rank = []\n",
    "    for index, row in df.iterrows():\n",
    "        season = row[\"season\"]\n",
    "        season = season - 1\n",
    "        if str(row[team]) in dct:\n",
    "            if str(season) in dct[str(row[team])]:\n",
    "                rank.append(dct[str(row[team])][str(season)].value)\n",
    "            else:\n",
    "                max_appear = max_appearance_rank(dct, season)\n",
    "                rank.append(max_appear)\n",
    "        else:\n",
    "            max_appear = max_appearance_rank(dct, season)\n",
    "            rank.append(max_appear)\n",
    "    return rank\n",
    "\n",
    "def get_data(dct, statistics):\n",
    "    statistics[\"home_team.overall_rank\"] = get_rank(statistics, dct[0], \"home_team.id\")\n",
    "    statistics[\"away_team.overall_rank\"] = get_rank(statistics, dct[0], \"away_team.id\")\n",
    "    statistics[\"home_team.ranking\"] = get_rank(statistics, dct[1], \"home_team.id\")\n",
    "    statistics[\"away_team.ranking\"] = get_rank(statistics, dct[2], \"away_team.id\")\n",
    "    statistics[\"home_team.real_rank\"] = get_rank(statistics, dct[3], \"home_team.id\")\n",
    "    statistics[\"away_team.real_rank\"] = get_rank(statistics, dct[3], \"away_team.id\")\n",
    "    return statistics, statistics[\"home_team.overall_rank\"].values.reshape(-1, 1), statistics[\"away_team.overall_rank\"].values.reshape(-1, 1), statistics[\"home_team.ranking\"].values.reshape(-1, 1), statistics[\"away_team.ranking\"].values.reshape(-1, 1),statistics[\"home_team.real_rank\"].values.reshape(-1, 1), statistics[\"away_team.real_rank\"].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(df, method=None, season=None, week=None):\n",
    "    # GET median for team_home.stats_home. team_home.stats_away. team_away.stats_home. team_away.stats_away.\n",
    "    # Filter df according to method\n",
    "    if method == '1':\n",
    "        print(\"Current and past season median\")\n",
    "        df = df[(df[\"season\"].isin([season, season-1]))]\n",
    "    elif method == '2':\n",
    "        print(\"Current and all past seasons median\")\n",
    "        df = df[(df[\"season\"] <= season)]\n",
    "    elif method == '3':\n",
    "        print(\"Current season only median\")\n",
    "        # First and second week zero/one home/away games\n",
    "        if week > 3:\n",
    "            df = df[(df[\"season\"] == season)]\n",
    "        else:\n",
    "            df = df[(df[\"season\"].isin([season, season-1]))]\n",
    "    elif method == '4':\n",
    "        print(\"Last 5 games median\")\n",
    "        if week > 5:\n",
    "            weeks = [w for w in range(week-1, week-6, -1)]\n",
    "            df = df[(df[\"season\"] == season) & (df[\"week\"].isin(weeks))]\n",
    "        else:\n",
    "            df = df[(df[\"season\"].isin([season, season-1]))]\n",
    "        \n",
    "    # Median home\n",
    "    extra_columns = df.filter([\"goals_home\"]).columns\n",
    "    columns_home = df.filter(regex='^stats_home').columns\n",
    "    columns_home = columns_home.append(extra_columns)\n",
    "    median_home = df.groupby(['home_team.id'], as_index=True)[columns_home].median()\n",
    "    # Median away\n",
    "    extra_columns = df.filter([\"goals_away\"]).columns\n",
    "    columns_away = df.filter(regex='^stats_away').columns\n",
    "    columns_away = columns_away.append(extra_columns)\n",
    "    median_away = df.groupby(['away_team.id'], as_index=True)[columns_away].median()\n",
    "    if method == '5':\n",
    "        print(\"Current season only mean\")\n",
    "        # First and second week zero/one home/away games\n",
    "        if week > 3:\n",
    "            df = df[(df[\"season\"] == season)]\n",
    "        else:\n",
    "            df = df[(df[\"season\"].isin([season, season-1]))]\n",
    "        mean_home = df.groupby(['home_team.id'], as_index=True)[columns_home].mean()\n",
    "        mean_away = df.groupby(['away_team.id'], as_index=True)[columns_away].mean()\n",
    "        return mean_home, mean_away\n",
    "    return median_home, median_away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_set(df, teams, season, week, pezzali=True, method=None, extras=None):\n",
    "    columns_home = [\"goals_home\", \"stats_home.c_red\", \"stats_home.s_total\", \"stats_home.s_off_g\", \"stats_home.s_on_g\", \"stats_home.s_in\", \n",
    "                   \"stats_home.saves\", \"stats_home.s_blocked\", \"stats_home.c_yellow\", \"stats_home.s_out\"]\n",
    "    columns_away = [\"goals_away\", \"stats_away.c_red\", \"stats_away.s_total\", \"stats_away.s_off_g\", \"stats_away.s_on_g\", \"stats_away.s_in\", \n",
    "                   \"stats_away.saves\", \"stats_away.s_blocked\", \"stats_away.c_yellow\", \"stats_away.s_out\"]\n",
    "    columns = [\"season\", \"week\"]\n",
    "    columns = columns_home + columns_away + columns\n",
    "    columns_pezzali = columns\n",
    "    \n",
    "    if pezzali == False or method == '5' or extras == '4' or extras == '3':\n",
    "        extra_columns = df.filter([\"goals_home\"]).columns\n",
    "        columns_home = df.filter(regex='^stats_home').columns\n",
    "        columns_home = columns_home.append(extra_columns)\n",
    "        extra_columns = df.filter([\"goals_away\"]).columns\n",
    "        columns_away = df.filter(regex='^stats_away').columns\n",
    "        columns_away = columns_away.append(extra_columns)\n",
    "        columns = columns_home.append(columns_away)\n",
    "        \n",
    "    \n",
    "    test_set = pd.DataFrame(columns=columns)\n",
    "    home_teams = [match[0] for match in teams]\n",
    "    away_teams = [match[1] for match in teams]\n",
    "    seasons = [season for i in range(0, len(teams))]\n",
    "    weeks = [week for i in range(0, len(teams))]\n",
    "    test_set[\"home_team.id\"] = home_teams\n",
    "    test_set[\"away_team.id\"] = away_teams\n",
    "    test_set[\"season\"] = seasons\n",
    "    test_set[\"week\"] = weeks\n",
    "    \n",
    "    columns_home = test_set.filter(columns_home).columns\n",
    "    columns_away = test_set.filter(columns_away).columns\n",
    "    i_th = test_set.columns.get_loc(\"home_team.id\")\n",
    "    i_ta = test_set.columns.get_loc(\"away_team.id\")\n",
    "    \n",
    "    median_home, median_away = get_median(df, method, season, week)\n",
    "\n",
    "    for i in range(0, len(test_set)):\n",
    "        for index, row in median_home.iterrows():\n",
    "            if test_set.iloc[i,i_th] == index:\n",
    "                for c in columns_home:\n",
    "                    try:\n",
    "                        i_c = test_set.columns.get_loc(c)\n",
    "                        test_set.iloc[i,i_c] = row[c]\n",
    "                    except:\n",
    "                        print(index, c)\n",
    "    for i in range(0, len(test_set)):\n",
    "        for index, row in median_away.iterrows():\n",
    "            if test_set.iloc[i,i_ta] == index:\n",
    "                for c in columns_away:\n",
    "                    try:\n",
    "                        i_c = test_set.columns.get_loc(c)\n",
    "                        test_set.iloc[i,i_c] = row[c]\n",
    "                    except:\n",
    "                        print(index, c)\n",
    "    # For non existing teams (this means ascending teams filled with median of column)\n",
    "    test_set = test_set.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "    if method == '5':\n",
    "        test_set = linear_reg(test_set, columns)\n",
    "        if pezzali == True and extras == '1':\n",
    "            return test_set[['week','season','away_team.id', 'home_team.id', 'goals_home', 'stats_home.s_off_g', 'stats_home.s_on_g', 'stats_home.s_in', 'stats_home.saves', 'stats_home.s_blocked', 'stats_home.c_yellow', 'stats_home.s_out', 'goals_away', 'stats_away.s_off_g', 'stats_away.s_on_g', 'stats_away.s_in', 'stats_away.saves', 'stats_away.s_blocked', 'stats_away.c_yellow', 'stats_away.s_out', 'stats_home.s_total', 'stats_away.s_total', 'stats_home.c_red']]\n",
    "    return test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the linear regression model, loads pretrains and returns the prediction\n",
    "def get_regression(row, column):\n",
    "    global country\n",
    "    # Load model\n",
    "    filename = 'model/' + country + '/' + column + '.sav'\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    row = row.drop(column)\n",
    "    row = row.drop(\"home_team.id\")\n",
    "    row = row.drop(\"away_team.id\")\n",
    "    row = row.drop(\"season\")\n",
    "    row = row.drop(\"week\")  \n",
    "    pred = np.array(row).reshape(1, -1)\n",
    "    return model.predict(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the test set for all columns calculating linear regression\n",
    "def linear_reg(test_set, columns):\n",
    "    for i in range(0, len(test_set)):\n",
    "        for c in columns:\n",
    "            try:\n",
    "                i_c = test_set.columns.get_loc(c)\n",
    "                test_set.iloc[i,i_c] = get_regression(test_set.iloc[i], c)\n",
    "            except:\n",
    "                print(i, c)\n",
    "                raise\n",
    "    return test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    A proper evaluation: we cannot test week 10 2018 with week 20 2018\n",
    "    The sequence of events must be maintained\n",
    "\"\"\"\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "def subtraining_trainset(df, season, week, up_to_season):\n",
    "    df_sub = df[(df[\"season\"] == season) & (df[\"week\"] < week)]\n",
    "    target = []\n",
    "    past_seasons = [s for s in range(up_to_season, season)]\n",
    "    \n",
    "    df_past = df[(df[\"season\"].isin(past_seasons))]\n",
    "    \n",
    "    df_sub = df_sub.append(df_past)\n",
    "    \n",
    "    for index, row in df_sub.iterrows():\n",
    "        target.append(playstyle.get_status(row))\n",
    "    \n",
    "    return df_sub, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data found to be not relevant to models\n",
    "# If not using Anova\n",
    "def remove_before_models(df, extras, if_anova=False):\n",
    "    if extras != '1':\n",
    "        if not if_anova or if_anova == 'both':\n",
    "            try:\n",
    "                df = df.drop(columns=['stats_home.c_yellow', 'stats_away.c_yellow', 'stats_home.p_accurate','stats_away.p_accurate','stats_away.p_total','stats_away.fouls','stats_home.p_total','stats_home.fouls','stats_home.corners','stats_home.offside','stats_away.corners','stats_away.offside'], axis=1)\n",
    "            except:\n",
    "                print(\"NO\")\n",
    "        try:\n",
    "            df = df.drop(columns=['index'], axis=1)\n",
    "        except:\n",
    "            print(\"\")\n",
    "        try:\n",
    "            df = df.drop(columns=['stats_home','stats_away'], axis=1)\n",
    "        except:\n",
    "            print(\"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This function returns a training set with the given method\n",
    "\"\"\"\n",
    "def train_method(dct, train_set, s, w, seasons, method, extras=None, if_anova=False):\n",
    "    print(\"Train Method\")\n",
    "    statistics_subset = None\n",
    "    target = None\n",
    "    if method == '1':\n",
    "        print(\"Current and past season median\")\n",
    "    elif method == '2':\n",
    "        print(\"Current and all past seasons median\")\n",
    "    elif method == '3':\n",
    "        print(\"Current season only median\")\n",
    "    elif method == '4':\n",
    "        print(\"Last 5 games median\")\n",
    "    elif method == '5':\n",
    "        print(\"Current and past season linear regression\")\n",
    "    elif method == '6':\n",
    "        print(\"Current and all past seasons linear regression\")\n",
    "    elif method == '7':\n",
    "        print(\"Current season only linear regression\")\n",
    "    elif method == '8':\n",
    "        print(\"Plain train set: all games from past seasons\")\n",
    "        statistics_subset, target = subtraining_trainset(train_set, s, w, seasons)\n",
    "   \n",
    "    # If something must be removed\n",
    "    statistics_removed = remove_before_models(statistics_subset, extras, if_anova)\n",
    "    n = 10\n",
    "    if extras == '1':\n",
    "        print(\"Applies pezzali to train set\")\n",
    "        statistics_subset = playstyle.pezzali_data(statistics_subset, is_train=True)\n",
    "        statistics_subset,_,_,_,_,_,_ = get_data(dct, statistics_subset)\n",
    "        statistics_subset = statistics_subset.drop(columns=['home_team.id', 'away_team.id', 'home_team.name', 'away_team.name', 'season', 'week'])\n",
    "    elif extras == '2':\n",
    "        print(\"Applies pca to train set\")\n",
    "        statistics_subset,ho,ao,hr,ar,rh,ra = get_data(dct, statistics_removed)\n",
    "        statistics_subset = statistics_subset.drop(columns=['home_team.id', 'away_team.id', 'home_team.name', 'away_team.name', 'goals_away','goals_home','season','week'])\n",
    "        pca = PCA(n_components=n)\n",
    "        statistics_subset = pca.fit_transform(statistics_subset)\n",
    "        statistics_subset = np.append(statistics_subset, ho, axis=1)\n",
    "        statistics_subset = np.append(statistics_subset, ao, axis=1)\n",
    "        statistics_subset = np.append(statistics_subset, hr, axis=1)\n",
    "        statistics_subset = np.append(statistics_subset, ar, axis=1)\n",
    "        statistics_subset = np.append(statistics_subset, rh, axis=1)\n",
    "        statistics_subset = np.append(statistics_subset, ra, axis=1)\n",
    "    elif extras == '3':\n",
    "        print(\"Adds pezzali and then pca to train set\")\n",
    "        statistics_subset = playstyle.pezzali_data(statistics_removed, is_train=True, both=True)\n",
    "        statistics_subset,ho,ao,hr,ar,rh,ra = get_data(dct, statistics_subset)\n",
    "        statistics_subset = statistics_subset.drop(columns=['home_team.id', 'away_team.id', 'home_team.name', 'away_team.name', 'goals_away','goals_home','season','week'])\n",
    "        pca = PCA(n_components=n)\n",
    "        statistics_subset = pca.fit_transform(statistics_subset)\n",
    "        statistics_subset = np.append(statistics_subset, ho, axis=1)\n",
    "        statistics_subset = np.append(statistics_subset, ao, axis=1)\n",
    "        statistics_subset = np.append(statistics_subset, hr, axis=1)\n",
    "        statistics_subset = np.append(statistics_subset, ar, axis=1)\n",
    "        statistics_subset = np.append(statistics_subset, rh, axis=1)\n",
    "        statistics_subset = np.append(statistics_subset, ra, axis=1)\n",
    "    elif extras == '4':\n",
    "        print(\"Adds pezzali to plain train set\")\n",
    "        statistics_subset = playstyle.pezzali_data(statistics_removed, is_train=True, both=True)\n",
    "        statistics_subset,ho,ao,hr,ar,rh,ra = get_data(dct, statistics_removed)\n",
    "        statistics_subset = statistics_subset.drop(columns=['home_team.id', 'away_team.id', 'home_team.name', 'away_team.name', 'goals_away','goals_home','season','week'])\n",
    "    elif extras == '0':\n",
    "        print(\"Plain train set with clusters\")\n",
    "        statistics_subset,_,_,_,_,_,_ = get_data(dct, statistics_removed)\n",
    "        statistics_subset = statistics_subset.drop(columns=['home_team.id', 'away_team.id','home_team.name', 'away_team.name','goals_away','goals_home','season','week'])\n",
    "    return statistics_subset, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_extras(dct, statistics_test, extras='0', if_anova=False):\n",
    "    # If something must be removed\n",
    "    statistics_removed = remove_before_models(statistics_test, extras, if_anova)\n",
    "    n = 10\n",
    "    if extras == '1':\n",
    "        print(\"Applies pezzali to test set\")\n",
    "        # Get test pezalli and mappings\n",
    "        statistics_test = playstyle.pezzali_data(statistics_test, is_train=False)\n",
    "        statistics_test,_,_,_,_,_,_ = get_data(dct, statistics_test)\n",
    "        try:\n",
    "            statistics_test = statistics_test.drop(columns=['home_team.id', 'away_team.id', 'season','week'])\n",
    "        except:\n",
    "            print(\"\")\n",
    "    elif extras == '2':\n",
    "        print(\"Applies pca to test set\")\n",
    "        statistics_test,ho,ao,hr,ar,rh,ra = get_data(dct, statistics_test)\n",
    "        pca = PCA(n_components=n)\n",
    "        statistics_test = pca.fit_transform(statistics_removed)\n",
    "        statistics_test = np.append(statistics_test, ho, axis=1)\n",
    "        statistics_test = np.append(statistics_test, ao, axis=1)\n",
    "        statistics_test = np.append(statistics_test, hr, axis=1)\n",
    "        statistics_test = np.append(statistics_test, ar, axis=1)\n",
    "        statistics_test = np.append(statistics_test, rh, axis=1)\n",
    "        statistics_test = np.append(statistics_test, ra, axis=1)\n",
    "    elif extras == '3':\n",
    "        print(\"Adds pezzali and then pca to test set\")\n",
    "        statistics_removed = playstyle.pezzali_data(statistics_removed, is_train=False, both=True)\n",
    "        statistics_removed = statistics_removed.drop(columns=['home_team.id', 'away_team.id', 'goals_away','goals_home','season','week'])\n",
    "        statistics_test,ho,ao,hr,ar,rh,ra = get_data(dct, statistics_test)\n",
    "        pca = PCA(n_components=n)\n",
    "        statistics_test = pca.fit_transform(statistics_removed)\n",
    "        statistics_test = np.append(statistics_test, ho, axis=1)\n",
    "        statistics_test = np.append(statistics_test, ao, axis=1)\n",
    "        statistics_test = np.append(statistics_test, hr, axis=1)\n",
    "        statistics_test = np.append(statistics_test, ar, axis=1)\n",
    "        statistics_test = np.append(statistics_test, rh, axis=1)\n",
    "        statistics_test = np.append(statistics_test, ra, axis=1)\n",
    "    elif extras == '4':\n",
    "        print(\"Adds pezzali to plain test set\")\n",
    "        statistics_removed = playstyle.pezzali_data(statistics_removed, is_train=False, both=True)\n",
    "        statistics_removed = statistics_removed.drop(columns=['home_team.id', 'away_team.id', 'goals_away','goals_home','season','week'])\n",
    "        statistics_test,ho,ao,hr,ar,rh,ra = get_data(dct, statistics_test)\n",
    "        statistics_test = np.append(statistics_removed, ho, axis=1)\n",
    "        statistics_test = np.append(statistics_test, ao, axis=1)\n",
    "        statistics_test = np.append(statistics_test, hr, axis=1)\n",
    "        statistics_test = np.append(statistics_test, ar, axis=1)\n",
    "        statistics_test = np.append(statistics_test, rh, axis=1)\n",
    "        statistics_test = np.append(statistics_test, ra, axis=1)\n",
    "    elif extras == '0':\n",
    "        print(\"Plain test set with clusters\")\n",
    "        statistics_test,_,_,_,_,_,_ = get_data(dct, statistics_removed)\n",
    "        statistics_test = statistics_test.drop(columns=['home_team.id', 'away_team.id','goals_away','goals_home','season','week'])\n",
    "    return statistics_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, clusters_dct, teams, season, week, test_m='1', extras='1', up_to_season=2017, classifier='rforest', if_anova=False, k_best=10):\n",
    "    \"\"\"\n",
    "        teams: the list of pair of teams' ids as [[10, 20], [30, 20]]\n",
    "    \"\"\"\n",
    "        \n",
    "    classifiers = dict(nb_ovo=OneVsOneClassifier(GaussianNB()),\n",
    "                       svc_ovo=OneVsOneClassifier(SVC(kernel='linear', probability=True)),\n",
    "                       ridge=OneVsOneClassifier(RidgeClassifierCV(class_weight='balanced')), \n",
    "                       rforest=OneVsOneClassifier(RandomForestClassifier(random_state=0, criterion=\"entropy\", max_features=\"log2\", min_samples_leaf=2)))\n",
    "    \n",
    "    if extras == '2' or extras == '0':\n",
    "        p = False\n",
    "    else:\n",
    "        p = True\n",
    "        \n",
    "    # Divide the training set to predict\n",
    "    statistics_train, target = train_method(clusters_dct, df, season, week, up_to_season, method='8', extras=extras, if_anova=if_anova)\n",
    "    # Creates the test set\n",
    "    statistics_test = create_test_set(statistics_to_test, teams, season, week, p, test_m, extras)\n",
    "    statistics_test = test_extras(clusters_dct, statistics_test, extras, if_anova)\n",
    "    # Scale the training and test set\n",
    "    st = preprocessing.StandardScaler().fit_transform(statistics_train)\n",
    "    sp = preprocessing.StandardScaler().fit_transform(statistics_test)\n",
    "    # Makes the prediction given a classifier\n",
    "    # 1) anova filter, take n best ranked features\n",
    "    if if_anova == True or if_anova == 'both':\n",
    "        anova_filter = SelectKBest(f_regression, k=k_best)\n",
    "        clf = make_pipeline(anova_filter, classifiers[classifier])\n",
    "    else:\n",
    "        clf = classifiers[classifier]\n",
    "    clf.fit(st, target)\n",
    "    Y = clf.predict(sp)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maps_results(teams, results, dct, season):\n",
    "    for i in range(0, len(results)):\n",
    "        home_team = dct[0][str(teams[i][0])][str(season)].name\n",
    "        away_team = dct[0][str(teams[i][1])][str(season)].name\n",
    "        print(\"home_team= %s, away_team= %s, result= %s\" %(home_team, away_team, str(results[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Everything to retrieve the data\n",
    "\"\"\"\n",
    "global country\n",
    "country = 'ES'\n",
    "league = '140'\n",
    "curr_week = 6\n",
    "season = 2020\n",
    "\n",
    "# Dictionary for the clusters (clusters from 2016 - 2019)\n",
    "dct = get_clusters(country, league, season, year_window=5)\n",
    "\n",
    "# Dataframe for the match (test from 2017 to 2019)\n",
    "statistics_to_test, target = get_statistics(country, league, curr_week, season, year_window=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Method\n",
      "Plain train set: all games from past seasons\n",
      "Applies pezzali to train set\n",
      "Current season only median\n",
      "Applies pezzali to test set\n",
      "home_team= Alaves - 2020, away_team= Elche - 2020, result= -1\n",
      "home_team= Athletic Club - 2020, away_team= Levante - 2020, result= -1\n",
      "home_team= Real Betis - 2020, away_team= Real Sociedad - 2020, result= 0\n",
      "home_team= Celta Vigo - 2020, away_team= Atletico Madrid - 2020, result= 1\n",
      "home_team= Eibar - 2020, away_team= Osasuna - 2020, result= 0\n",
      "home_team= Getafe - 2020, away_team= Barcelona - 2020, result= 1\n",
      "home_team= Granada CF - 2020, away_team= Sevilla - 2020, result= 1\n",
      "home_team= Huesca - 2020, away_team= Valladolid - 2020, result= 1\n",
      "home_team= Real Madrid - 2020, away_team= Cadiz - 2020, result= 0\n",
      "home_team= Villarreal - 2020, away_team= Valencia - 2020, result= 1\n"
     ]
    }
   ],
   "source": [
    "# TODO: MAP clusters on current season\n",
    "teams = [[542, 797], [531, 539], [543, 548], [538, 530], [545, 727], [546, 529], [715, 536], [726, 720], [541, 724], [533, 532]]\n",
    "week = 7\n",
    "results = predict(statistics_to_test, dct, teams, season, week, test_m='3', extras='1', if_anova='both', classifier='ridge')\n",
    "maps_results(teams, results, dct, season)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
